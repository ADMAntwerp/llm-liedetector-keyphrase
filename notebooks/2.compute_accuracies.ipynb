{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import yaml\n",
    "import torch\n",
    "import os\n",
    "from transformers import (AutoTokenizer, AutoModelForCausalLM)\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pickle\n",
    "import warnings\n",
    "import itertools\n",
    "from evaluation_tools import compute_metrics_crossval\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First some parameters and functions that remain constant for the rest of the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_names=[\"cities\", \"neg_cities\", \"sp_en_trans\", \"neg_sp_en_trans\", \"inventors\",\n",
    "\"neg_inventors\", \"animal_class\", \"neg_animal_class\", \"element_symb\", \"neg_element_symb\"]\n",
    "LAYERS=[12,14,16,18,20]\n",
    "\n",
    "#### CHOOSE FROM THE 2 LLMS\n",
    "model_options=[\"Llama3-8b-instruct\", \"Mistral-8b-instruct\"]\n",
    "model_name=\"Llama3-8b-instruct\"\n",
    "\n",
    "#### CHOOSE FROM THE PROBES \n",
    "#(note that one should not rely on the TTPD figures for anything besides the original training set because we have not explored how polarities would work in the conversational formats)\n",
    "probe_options=[\"LRC\",\"LR\",\"PCA\",\"TTPD\"]\n",
    "probe_name=\"TTPD\"\n",
    "\n",
    "### NUMBER OF ITERATIONS TO AVERAGE OUT REBALANCING RANDOMNESS \n",
    "N=5\n",
    "\n",
    "### CREATE SUBDIR WHERE FIGS AND CSVs WILL BE SAVED\n",
    "save_dir=f\"figures/{model_name}/{probe_name}\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "def root_paths(keyphrase,layer):\n",
    "\n",
    "    root_path_format_1=f\"data/acts/{model_name}/layer_{layer}/format1_{keyphrase}\"\n",
    "    root_path_format_2=f\"data/acts/{model_name}/layer_{layer}/format2_{keyphrase}\"\n",
    "    root_path_format_3=f\"data/acts/{model_name}/layer_{layer}/format3_{keyphrase}\"\n",
    "\n",
    "    original=f\"data/acts/{model_name}/layer_{layer}/original\"\n",
    "\n",
    "    formats=[ root_path_format_1, root_path_format_2,root_path_format_3]\n",
    "\n",
    "    return original, formats\n",
    "\n",
    "\n",
    "def return_generalization_matrix(train_formats, test_formats, N, probe_type):\n",
    "\n",
    "    print(f\"computing generalization matrix for {probe_type} probe\")\n",
    "\n",
    "    generalization_matrices= np.zeros(shape=(len(train_formats),len(test_formats)))\n",
    "\n",
    "    for i, format_row  in enumerate(train_formats):\n",
    "        for j,format_columns in enumerate(test_formats):\n",
    "            \n",
    "            accuracies_dict, average_accuracy_dict=compute_metrics_crossval(root_path_train=format_row,root_path_test=format_columns,  topic_names=ds_names, probes=[probe_type], N=N)\n",
    "                                                                                    \n",
    "            generalization_matrices[i,j]=average_accuracy_dict[probe_type]\n",
    "    \n",
    "    return generalization_matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 1: How well does the truth direction generalize from statements to prompts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_matrix=np.zeros(shape=(7,len(LAYERS)))\n",
    "\n",
    "for i, layer in enumerate(LAYERS):\n",
    "    \n",
    "    original, test_formats_standard=root_paths(\"none\", layer)\n",
    "    _, test_formats_longer=root_paths(\"longer\", layer)\n",
    "\n",
    "    train_formats=[original]\n",
    "    test_formats=[original]+test_formats_standard+test_formats_longer\n",
    "    generalization_matrices=return_generalization_matrix(train_formats, test_formats, N, probe_name)\n",
    "    layer_matrix[:,i]=generalization_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[\"original\",\"F1\",\"F2\",\"F3\",\"F1+L\",\"F2+L\",\"F3+L\"]\n",
    "shapes=[\"o\"]+[\"s\"]*3+[\"v\"]*3\n",
    "linestyles=[\"-\"]+[\"--\"]*3+[\"-.\"]*3\n",
    "plt.figure(i)\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    plt.plot(LAYERS, layer_matrix[i,:], linestyle=linestyles[i], marker= shapes[i], label=labels[i]  )\n",
    "\n",
    "plt.ylim([0.3,1])\n",
    "plt.legend(loc=\"lower right\",ncol=2)\n",
    "plt.xlabel(\"layer\")\n",
    "plt.ylabel(\"acc\")\n",
    "plt.xticks(LAYERS)\n",
    "plt.title(probe_name)\n",
    "\n",
    "\n",
    "plt.savefig(f\"{save_dir}/original_generalization\", dpi=300)\n",
    "df = pd.DataFrame(layer_matrix, index=labels, columns=LAYERS).transpose()\n",
    "df.index.name = 'layer'\n",
    "df.to_csv(f\"{save_dir}/original_generalization.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2: How does the truth direction generalize from format 1? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYERS=[12,14,16,18,20]\n",
    "\n",
    "layer_matrix=np.zeros(shape=(6,len(LAYERS)))\n",
    "\n",
    "for i, layer in enumerate(LAYERS):\n",
    "    original, standard_formats=root_paths(\"none\", layer)\n",
    "    _, longer_formats=root_paths(\"longer\", layer)\n",
    "    train_formats=standard_formats[0:1]\n",
    "    test_formats=standard_formats+longer_formats\n",
    "    generalization_matrices=return_generalization_matrix(train_formats, test_formats, N, probe_name)\n",
    "    layer_matrix[:,i]=generalization_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[\"F1\",\"F2\",\"F3\",\"F1+L\",\"F2+L\",\"F3+L\"]\n",
    "shapes=[\"o\"]+[\"s\"]*2+[\"v\"]*3\n",
    "linestyles=[\"-\"]+[\"--\"]*2+[\"-.\"]*3\n",
    "\n",
    "\n",
    "plt.figure(i)\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    plt.plot(LAYERS, layer_matrix[i,:], linestyle=linestyles[i], marker= shapes[i], label=labels[i]  )\n",
    "\n",
    "plt.ylim([0.3,1])\n",
    "plt.legend(loc=\"lower right\",ncol=2)\n",
    "plt.xlabel(\"layer\")\n",
    "plt.ylabel(\"gen_acc\")\n",
    "plt.xticks(LAYERS)\n",
    "plt.title(f\"{probe_name} trained on format 1\")\n",
    "\n",
    "plt.savefig(f\"{save_dir}/format1_generalization\", dpi=300)\n",
    "df = pd.DataFrame(layer_matrix, index=labels, columns=LAYERS).transpose()\n",
    "df.index.name = 'layer'\n",
    "df.to_csv(f\"{save_dir}/format1_generalization.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 3: Heatmap for all F -> F+L cross-accuracies fixed layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYER=18\n",
    "\n",
    "original, formats1=root_paths(\"none\", LAYER)\n",
    "_, formats2=root_paths(\"longer\", LAYER)\n",
    "\n",
    "formats_train=formats1\n",
    "formats_test=formats1+formats2 \n",
    "generalization_matrices=return_generalization_matrix(formats_train, formats_test, N, probe_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "row_labels = [f\"F{i}\" for i in range(1,4)]\n",
    "col_labels = (\n",
    "    [f\"F{i}\" for i in range(1,4)]\n",
    "    + [f\"F{i}+L\" for i in range(1,4)]\n",
    ")\n",
    " \n",
    "df = pd.DataFrame(generalization_matrices, index=row_labels, columns=col_labels)\n",
    "\n",
    "longer_cols   = [f\"F{i}+L\" for i in range(1, 4)]\n",
    "longer_avg    = df[longer_cols].mean(axis=1)              \n",
    "overall_avg   = df.mean(axis=1)                         \n",
    "\n",
    "row_averages = pd.DataFrame(\n",
    "    {\"Row Avg\": overall_avg,\"Longer Avg\": longer_avg},\n",
    "    index=df.index\n",
    ")\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "gs = gridspec.GridSpec(ncols=2, nrows=1, width_ratios=[4, 0.5])\n",
    "\n",
    "ax0 = fig.add_subplot(gs[0, 0])\n",
    "ax1 = fig.add_subplot(gs[0, 1], sharey=ax0)   \n",
    "\n",
    "sns.heatmap(\n",
    "    df,\n",
    "    annot=True,\n",
    "    cmap=\"coolwarm\",\n",
    "    xticklabels=df.columns,\n",
    "    yticklabels=df.index,\n",
    "    ax=ax0,\n",
    "    vmin=0.5,\n",
    "    vmax=1\n",
    ")\n",
    "ax0.set_title(f\"Truth probe generalization matrix {probe_name}\")\n",
    "ax0.set_xticklabels(ax0.get_xticklabels(), rotation=45, ha=\"right\")\n",
    "ax0.set_yticklabels(ax0.get_yticklabels(), rotation=0)\n",
    "\n",
    "sns.heatmap(\n",
    "    row_averages,\n",
    "    annot=True,\n",
    "    cmap=\"coolwarm\",\n",
    "    cbar=False,             \n",
    "    yticklabels=df.index,\n",
    "    ax=ax1,\n",
    "    vmin=0.5,\n",
    "    vmax=1\n",
    ")\n",
    "ax1.set_xticks([])          \n",
    "ax1.set_title(\"Full row/Longer avg\")    \n",
    "ax1.set_yticklabels(ax1.get_yticklabels(), rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f\"{save_dir}/layer-18-heatmap-standard\", dpi=300)\n",
    "df_rounded = df.round(2)\n",
    "df_rounded.to_csv(f\"{save_dir}/layer-18-heatmap-standard.csv\", sep=' ', header=False, index=False, float_format='%.2f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 4: Introducing Keyphrase. Let's compare F->F+L to F+K -> F+L+K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYERS=[12,14,16,18,20]\n",
    "\n",
    "generalization_matrix_standard=np.zeros(shape=(3,len(LAYERS)))\n",
    "generalization_matrix_keyphrase=np.zeros(shape=(3,len(LAYERS)))\n",
    "\n",
    "\n",
    "for i, layer in enumerate(LAYERS):\n",
    "\n",
    "\n",
    "    _, none=root_paths(\"none\", layer)\n",
    "    _, longer=root_paths(\"longer\", layer)\n",
    "    _, keyphrase=root_paths(\"keyphrase\", layer)\n",
    "    _, longer_keyphrase=root_paths(\"longer_keyphrase\", layer)\n",
    "\n",
    "    for j in range(0,3):\n",
    "\n",
    "        formats_standard=none[j:j+1]\n",
    "        formats_keyphrase=keyphrase[j:j+1]\n",
    "\n",
    "        formats_longer=longer[j:j+1]\n",
    "        formats_longer_keyphrase=longer_keyphrase[j:j+1]\n",
    "\n",
    "        generalization_acc_standard=return_generalization_matrix(formats_standard, formats_longer, N, probe_name)\n",
    "        generalization_acc_keyphrase=return_generalization_matrix(formats_keyphrase, formats_longer_keyphrase, N, probe_name)\n",
    "\n",
    "        generalization_matrix_standard[j,i]=generalization_acc_standard[0,0]\n",
    "        generalization_matrix_keyphrase[j,i]=generalization_acc_keyphrase[0,0]\n",
    "        \n",
    "generalization_matrix=np.vstack((generalization_matrix_standard, generalization_matrix_keyphrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1=[\"F1 -> F1+L\" , \"F2 -> F2+L\" , \"F3 -> F3+L\"]\n",
    "labels2=[\"F1+K -> F1+L+K\", \"F2+K -> F2+L+K\" ,\"F3+K -> F3+L+K\" ]\n",
    "labels=labels1+labels2\n",
    "shapes=[\"s\"]*3+[\"v\"]*3\n",
    "linestyles=[\"--\"]*3+[\"-.\"]*3\n",
    "\n",
    "\n",
    "plt.figure(i)\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    plt.plot(LAYERS, generalization_matrix[i,:], linestyle=linestyles[i], marker= shapes[i], label=labels[i]  )\n",
    "\n",
    " \n",
    "plt.ylim([0.3,1])\n",
    "plt.legend(loc=\"lower right\",ncol=3)\n",
    "plt.xlabel(\"layer\")\n",
    "plt.ylabel(\"gen_acc\")\n",
    "plt.xticks(LAYERS)\n",
    "plt.title(f\"{probe_name} generalization from format to the same format with longer chat\")\n",
    "\n",
    "plt.savefig(f\"{save_dir}/short-long-generalization\", dpi=300)\n",
    "df = pd.DataFrame(generalization_matrix, index=labels, columns=LAYERS).transpose()\n",
    "df.index.name = 'layer'\n",
    "df.to_csv(f\"{save_dir}/short-long-generalization.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 5: Heatmap for F+K -> F+K+L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYER=18\n",
    "\n",
    "original, formats1=root_paths(\"keyphrase\", LAYER)\n",
    "_, formats2=root_paths(\"longer_keyphrase\", LAYER)\n",
    "\n",
    "\n",
    "formats_train=formats1\n",
    "formats_test=formats1+formats2\n",
    "\n",
    "generalization_matrices=return_generalization_matrix(formats_train, formats_test, N, probe_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_labels = [f\"F{i}+K\" for i in range(1,4)]\n",
    "col_labels = (\n",
    "    [f\"F{i}+K\" for i in range(1,4)]\n",
    "    + [f\"F{i}+L+K\" for i in range(1,4)]\n",
    ")\n",
    " \n",
    "df = pd.DataFrame(generalization_matrices, index=row_labels, columns=col_labels)\n",
    "\n",
    "longer_cols   = [f\"F{i}+L+K\" for i in range(1, 4)]\n",
    "longer_avg    = df[longer_cols].mean(axis=1)              # ←  ⟵ “Longer Avg”\n",
    "overall_avg   = df.mean(axis=1)                           # ←  ⟵ “Row Avg”\n",
    "\n",
    "row_averages = pd.DataFrame(\n",
    "    {\"Row Avg\": overall_avg,\"Longer Avg\": longer_avg},\n",
    "    index=df.index\n",
    ")\n",
    "\n",
    "fig = plt.figure(figsize=(13, 6))\n",
    "gs = gridspec.GridSpec(ncols=2, nrows=1, width_ratios=[4, 1])  # a bit wider\n",
    "\n",
    "# Main heatmap\n",
    "ax0 = fig.add_subplot(gs[0, 0])\n",
    "sns.heatmap(\n",
    "    df, annot=True, cmap=\"coolwarm\",\n",
    "    xticklabels=df.columns, yticklabels=df.index,\n",
    "    ax=ax0, vmin=0.5, vmax=1\n",
    ")\n",
    "ax0.set_title(f\"Truth‑probe generalization matrix {probe_name}\")\n",
    "ax0.set_xticklabels(ax0.get_xticklabels(), rotation=45, ha=\"right\")\n",
    "ax0.set_yticklabels(ax0.get_yticklabels(), rotation=0)\n",
    "\n",
    "# Two‑column heatmap for the averages\n",
    "ax1 = fig.add_subplot(gs[0, 1], sharey=ax0)\n",
    "sns.heatmap(\n",
    "    row_averages,\n",
    "    annot=True, cmap=\"coolwarm\", cbar=False,\n",
    "    yticklabels=df.index, ax=ax1, vmin=0.5, vmax=1\n",
    ")\n",
    "ax1.set_title(\"Full row/Longer avg\")   # label above the averages\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(), rotation=45, ha=\"right\")\n",
    "ax1.set_yticklabels(ax1.get_yticklabels(), rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f\"{save_dir}/layer18-generalization-keyphrase\", dpi=300)\n",
    "df_rounded = df.round(2)\n",
    "df_rounded.to_csv(f\"{save_dir}/layer18-generalization-keyphrase.csv\", sep=' ', header=False, index=False, float_format='%.2f')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 6: Control phrase?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYERS=[12,14,16,18,20]\n",
    "\n",
    "generalization_matrix_keyphrase=np.zeros(shape=(3,len(LAYERS)))\n",
    "generalization_matrix_control=np.zeros(shape=(3,len(LAYERS)))\n",
    "\n",
    "\n",
    "for i, layer in enumerate(LAYERS):\n",
    "\n",
    "\n",
    "    _, keyphrase=root_paths(\"keyphrase\", layer)\n",
    "    _, longer_keyphrase=root_paths(\"longer_keyphrase\", layer)\n",
    "    _, control=root_paths(\"control\", layer)\n",
    "    _, longer_control=root_paths(\"longer_control\", layer)\n",
    "\n",
    "    for j in range(0,3):\n",
    "\n",
    "        formats_keyphrase=keyphrase[j:j+1]\n",
    "        formats_control=control[j:j+1]\n",
    "\n",
    "        formats_longer_keyphrase=longer_keyphrase[j:j+1]\n",
    "        formats_longer_control=longer_control[j:j+1]\n",
    "\n",
    "        generalization_acc_keyphrase=return_generalization_matrix(formats_keyphrase, formats_longer_keyphrase, N, probe_name)\n",
    "        generalization_acc_control=return_generalization_matrix(formats_control, formats_longer_control, N, probe_name)\n",
    "\n",
    "        generalization_matrix_keyphrase[j,i]=generalization_acc_keyphrase[0,0]\n",
    "        generalization_matrix_control[j,i]=generalization_acc_control[0,0]\n",
    "        \n",
    "generalization_matrix=np.vstack((generalization_matrix_keyphrase, generalization_matrix_control))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### the rows in generalization matrix are now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1=[\"F1+K -> F1+L+K\", \"F2+K -> F2+L+K\" ,\"F3+K -> F3+L+K\" ]\n",
    "labels2=[\"F1+C -> F1+L+C\", \"F2+C -> F2+L+C\" ,\"F3+C -> F3+L+C\" ]\n",
    "\n",
    "colors=[\"red\",\"blue\",\"green\"]\n",
    "\n",
    "shapes1=[\"s\"]*3 \n",
    "shapes2=[\".\"]*3\n",
    "\n",
    "linestyles1=[\"-\"]*3 \n",
    "linestyles2=[\"--\"]*3 \n",
    "\n",
    "plt.figure(i)\n",
    "\n",
    "for i, label in enumerate(labels1):\n",
    "    plt.plot(LAYERS, generalization_matrix[i,:], linestyle=linestyles1[i], marker= shapes1[i], label=labels1[i], color=colors[i] )\n",
    "    plt.plot(LAYERS, generalization_matrix[i+3,:], linestyle=linestyles2[i], marker= shapes2[i], label=labels2[i], color=colors[i] )\n",
    "\n",
    "plt.ylim([0.5,1])\n",
    "plt.legend(loc=\"lower right\",ncol=3)\n",
    "plt.xlabel(\"layer\")\n",
    "plt.ylabel(\"gen_acc\")\n",
    "plt.xticks(LAYERS)\n",
    "plt.title(f\"{probe_name} comparison between keyphrase in main work and control kepyhrase\")\n",
    "\n",
    "plt.savefig(f\"{save_dir}/control_comparison\", dpi=300)\n",
    "df = pd.DataFrame(generalization_matrix, index=labels, columns=LAYERS).transpose()\n",
    "df.index.name = 'layer'\n",
    "df.to_csv(f\"{save_dir}/control_comparison.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
